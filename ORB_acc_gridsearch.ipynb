{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqwpPeHuURHD"
      },
      "source": [
        "Scopo degli algoritmi di Computer Vision da usare nel nostro progetto:\n",
        "\n",
        "\n",
        "    Input: Immagine \n",
        "\n",
        "         --> Detector [Immagine] = {Array di keypoints} \n",
        "\n",
        "         --> Descriptor [{Array di keypoints}] = {Matrice di features}\n",
        "\n",
        "(Ogni Keypoint viene descritto da un numero/tipo di features differenti che dipende dall'algoritmo usato. SIFT per esempio sta per \"Scale Invariant Feature Transform\" e si base su features preservabili da trasformazioni spaziali ([roto-traslazioni / restizioni-espansioni])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_hHei5VjJnQ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to the two folders\n",
        "folder_1_path = \"dataset/byteplot/malicious/\"\n",
        "folder_2_path = \"dataset/byteplot/benign/benign/\"\n",
        "folder_3_path = \"dataset/byteplot/benign/benign_edu/\"\n",
        "\n",
        "# Read the images in each folder and store them in a list\n",
        "images_1 = [cv2.imread(os.path.join(folder_1_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        "            for image_file in os.listdir(folder_1_path)]\n",
        "images_2 = [cv2.imread(os.path.join(folder_2_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        "            for image_file in os.listdir(folder_2_path)]\n",
        "images_3 = [cv2.imread(os.path.join(folder_3_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        "            for image_file in os.listdir(folder_3_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "random.shuffle(images_1)\n",
        "\n",
        "max_len_benign = len(images_2)+len(images_3)\n",
        "\n",
        "images_1 = images_1[:max_len_benign]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label each image with the respective label (1 for total_des_trainfolder_1, 2 for folder_2)\n",
        "labels_1 = [0 for _ in range(len(images_1))]\n",
        "labels_2 = [1 for _ in range(len(images_2)+len(images_3))]\n",
        "\n",
        "# Combine the images and labels into a single dataset\n",
        "images = images_1 + images_2 + images_3\n",
        "labels = labels_1 + labels_2\n",
        "\n",
        "X = images\n",
        "y = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5936\n",
            "5936\n"
          ]
        }
      ],
      "source": [
        "print(len(X))\n",
        "print(len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDjQzK9xteHt"
      },
      "source": [
        "Implementazione SIFT/ORB descriptors. Partendo dal file path, generiamo di nuovo il bytre plot, ma questa volta evidenziamo i keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define detector object\n",
        "nfeatures = 41\n",
        "detector = cv2.ORB_create(nfeatures)\n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "c=[]\n",
        "d=[]\n",
        "\n",
        "for image in X_train:\n",
        "    query_kps, query_des = detector.detectAndCompute(image, None)\n",
        "    a.append(query_kps)\n",
        "    b.append(query_des)\n",
        "\n",
        "for image in X_test:\n",
        "    query_kps, query_des = detector.detectAndCompute(image, None)\n",
        "    c.append(query_kps)\n",
        "    d.append(query_des)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_kps_train= a\n",
        "total_des_train= b\n",
        "total_kps_test= c\n",
        "total_des_test= d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_indexes_train = []\n",
        "\n",
        "for i,e in enumerate(total_des_train):\n",
        "    if e is None:\n",
        "        null_indexes_train.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_des_train = np.delete(total_des_train, null_indexes_train) \n",
        "y_train = np.delete(y_train,null_indexes_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_des_train = total_des_train.tolist()\n",
        "y_train = y_train.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_indexes_test = []\n",
        "\n",
        "for i,e in enumerate(total_des_test):\n",
        "    if e is None:\n",
        "        null_indexes_test.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_des_test = np.delete(total_des_test, null_indexes_test) \n",
        "y_test = np.delete(y_test,null_indexes_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_des_test = total_des_test.tolist()\n",
        "y_test = y_test.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "max0 = 0\n",
        "for des in total_des_train:\n",
        "    if des is not None:\n",
        "        if des.shape[0] > max0:\n",
        "            max0 = des.shape[0]\n",
        "\n",
        "max1=0\n",
        "for des in total_des_test:\n",
        "    if des is not None:\n",
        "        if des.shape[0] > max1:\n",
        "            max1 = des.shape[0]\n",
        "    \n",
        "if max1 > max0:\n",
        "    max0=max1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "for des in total_des_train:\n",
        "    padding_to_add = max0 - des.shape[0]\n",
        "    if padding_to_add != 0:\n",
        "        pad_list = []\n",
        "        for k in range(32):\n",
        "            pad_list.append(0)\n",
        "        for j in range(padding_to_add):\n",
        "            total_des_train[i] = np.append(total_des_train[i], pad_list)\n",
        "        total_des_train[i] = np.array(total_des_train[i]).reshape(max0,32)\n",
        "    i += 1\n",
        "\n",
        "i = 0\n",
        "for des in total_des_test:\n",
        "    padding_to_add = max0 - des.shape[0]\n",
        "    if padding_to_add != 0:\n",
        "        pad_list = []\n",
        "        for k in range(32):\n",
        "            pad_list.append(0)\n",
        "        for j in range(padding_to_add):\n",
        "            total_des_test[i] = np.append(total_des_test[i], pad_list)\n",
        "        total_des_test[i] = np.array(total_des_test[i]).reshape(max0,32)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = 0\n",
        "for des in total_des_train:\n",
        "    total_des_train[i] = np.hstack(des)\n",
        "    i += 1\n",
        "\n",
        "i = 0\n",
        "for des in total_des_test:\n",
        "    total_des_test[i] = np.hstack(des)\n",
        "    i += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "gridsearch (using accuracy as a metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.6798604187437687\n",
            "Standard deviation:  0.02729182707864323\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 4, 8],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create an instance of the RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create an instance of GridSearchCV\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(total_des_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Get the best classifier\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Use cross_val_score to evaluate the classifier with the best parameters\n",
        "scores = cross_val_score(best_clf, total_des_test, y_test, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the scores\n",
        "print(\"Mean accuracy: \", scores.mean())\n",
        "print(\"Standard deviation: \", scores.std())\n",
        "\n",
        "# Plot the results as a box plot\n",
        "plt.boxplot(scores, vert=False)\n",
        "plt.xlabel(\"F1-score\")\n",
        "plt.title(\"Cross-validation results\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If everything goes fine, I plotted the wrong x label, as this is the \"accuracy\" scoring. Needed editing in post production in case"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
