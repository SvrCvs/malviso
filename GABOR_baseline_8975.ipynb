{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm7Y6FjeKBn1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_hHei5VjJnQ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBXjIPq-iWwG",
        "outputId": "6e37e67d-99c4-4d82-8417-21463b3e41b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F87RpgJJiPK6"
      },
      "outputs": [],
      "source": [
        "# Define the path to the two folders\n",
        "#folder_1_path = '/content/drive/MyDrive/Dataset/byteplot/malicious'\n",
        "#folder_2_path = '/content/drive/MyDrive/Dataset/byteplot/benign/benign'\n",
        "#folder_3_path = '/content/drive/MyDrive/Dataset/byteplot/benign/benign_edu'\n",
        "new_folder_1_path = '/content/drive/MyDrive/Dataset/malicious_1000'\n",
        "new_folder_2_path = '/content/drive/MyDrive/Dataset/benign_1000'\n",
        "\n",
        "# Read the images in each folder and store them in a list\n",
        "images_1 = [cv2.imread(os.path.join(new_folder_1_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        "            for image_file in os.listdir(new_folder_1_path)]\n",
        "images_2 = [cv2.imread(os.path.join(new_folder_2_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        "            for image_file in os.listdir(new_folder_2_path)]\n",
        "#images_3 = [cv2.imread(os.path.join(folder_3_path, image_file), cv2.IMREAD_GRAYSCALE) \\\n",
        " #           for image_file in os.listdir(folder_3_path)]\n",
        "\n",
        "# Label each image with the respective label (1 for total_des_trainfolder_1, 2 for folder_2)\n",
        "labels_1 = [0 for _ in range(len(images_1))]\n",
        "labels_2 = [1 for _ in range (len(images_2))]\n",
        "#labels_2 = [1 for _ in range(len(images_2)+len(images_3))]\n",
        "\n",
        "# Combine the images and labels into a single dataset\n",
        "images = images_1 + images_2 #+ images_3\n",
        "labels = labels_1 + labels_2\n",
        "\n",
        "X = images\n",
        "y = labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tyg4TOB4K_kx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def gabor_filter(ksize, sigma, theta, lambd, gamma, psi):\n",
        "    filter_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, cv2.CV_32F)\n",
        "    return filter_kernel\n",
        "\n",
        "def apply_gabor_filter(img, filter_kernel):\n",
        "    filtered_img = cv2.filter2D(img, cv2.CV_8UC3, filter_kernel)\n",
        "    return filtered_img\n",
        "\n",
        "def extract_features(filtered_img):\n",
        "    mean = np.mean(filtered_img)\n",
        "    var = np.var(filtered_img)\n",
        "    feature_vector = np.concatenate((np.array([mean]), np.array([var])))\n",
        "    return feature_vector\n",
        "\n",
        "def Gabor_filter_extraction(img):\n",
        "    # Define the parameters for the 24 Gabor filters\n",
        "    ksize = 5\n",
        "    sigma_list = [1, 2, 3]\n",
        "    theta_list = [0, np.pi/8, np.pi/4, 3*np.pi/8]\n",
        "    lambd_list = [0.05, 0.25]\n",
        "    gamma = 0.5\n",
        "    psi = 0.0\n",
        "\n",
        "    filtered_img_list = []\n",
        "    for sigma in sigma_list:\n",
        "        for theta in theta_list:\n",
        "            for lambd in lambd_list:\n",
        "                # Create the filter kernel\n",
        "                filter_kernel = gabor_filter(ksize, sigma, theta, lambd, gamma, psi)\n",
        "                # Apply the filter to the image\n",
        "                filtered_img = apply_gabor_filter(img, filter_kernel)\n",
        "                filtered_img_list.append(filtered_img)\n",
        "    feature_vector = []\n",
        "    for i, filtered_img in enumerate(filtered_img_list):\n",
        "      filtered_img = cv2.normalize(filtered_img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
        "      features = extract_features(filtered_img)\n",
        "      feature_vector.append(features)\n",
        "\n",
        "    hist = cv2.calcHist([img], [0], None, [16], [0, 256])\n",
        "    feature_vector.append(hist)\n",
        "    return feature_vector\n"
      ],
      "metadata": {
        "id": "trGjffpiOja2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_des_test = [Gabor_filter_extraction(img) for img in X_test] "
      ],
      "metadata": {
        "id": "ndVsG5qda6VK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_des_train = [Gabor_filter_extraction(img) for img in X_train] "
      ],
      "metadata": {
        "id": "f2ec9m4cOq_8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the filters\n",
        "tot_train_features = []\n",
        "\n",
        "for i in total_des_train:\n",
        "  x = np.hstack(i[:24])\n",
        "  z = i[-1].flatten()\n",
        "  w = np.concatenate((x,z))\n",
        "  tot_train_features.append(w)"
      ],
      "metadata": {
        "id": "662P5DjbZiIf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_test_features = []\n",
        "\n",
        "for i in total_des_test:\n",
        "  x = np.hstack(i[:24])\n",
        "  z = i[-1].flatten()\n",
        "  w = np.concatenate((x,z))\n",
        "  tot_test_features.append(w)"
      ],
      "metadata": {
        "id": "wa-dBblIagwG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_test_features = np.array(tot_test_features)"
      ],
      "metadata": {
        "id": "fyz46uHAaxMx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_train_features = np.array(tot_train_features)"
      ],
      "metadata": {
        "id": "zf2APHc2aSm2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tot_test_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTsWkPB7aa5s",
        "outputId": "e8d68e6e-23e3-4efe-c0da-c9597f6f57fe"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "clf.fit(tot_train_features, y_train)\n",
        "\n",
        "score = clf.score(tot_test_features, y_test)\n",
        "print(\"Test accuracy:\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gnQUnToLIGu",
        "outputId": "6dd9593b-78c7-4439-9f84-b67b84b13043"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8975\n"
          ]
        }
      ]
    }
  ]
}