{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "X = np.load('/home/filsave/malviso/X.npy', allow_pickle=True)\n",
    "y = np.load('/home/filsave/malviso/y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def gabor_filter(ksize, sigma, theta, lambd, gamma, psi):\n",
    "    filter_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, cv2.CV_32F)\n",
    "    return filter_kernel\n",
    "\n",
    "def apply_gabor_filter(img, filter_kernel):\n",
    "    filtered_img = cv2.filter2D(img, cv2.CV_8UC3, filter_kernel)\n",
    "    return filtered_img\n",
    "\n",
    "def extract_features(filtered_img):\n",
    "    mean = np.mean(filtered_img)\n",
    "    var = np.var(filtered_img)\n",
    "    feature_vector = np.concatenate((np.array([mean]), np.array([var])))\n",
    "    return feature_vector\n",
    "\n",
    "def Gabor_filter_extraction(img):\n",
    "    # Define the parameters for the 24 Gabor filters\n",
    "    ksize = 5\n",
    "    sigma_list = [1, 2, 3]\n",
    "    theta_list = [0, np.pi/8, np.pi/4, 3*np.pi/8]\n",
    "    lambd_list = [0.05, 0.25]\n",
    "    gamma = 0.5\n",
    "    psi = 0.0\n",
    "\n",
    "    filtered_img_list = []\n",
    "    for sigma in sigma_list:\n",
    "        for theta in theta_list:\n",
    "            for lambd in lambd_list:\n",
    "                # Create the filter kernel\n",
    "                filter_kernel = gabor_filter(ksize, sigma, theta, lambd, gamma, psi)\n",
    "                # Apply the filter to the image\n",
    "                filtered_img = apply_gabor_filter(img, filter_kernel)\n",
    "                filtered_img_list.append(filtered_img)\n",
    "    feature_vector = []\n",
    "    for i, filtered_img in enumerate(filtered_img_list):\n",
    "      filtered_img = cv2.normalize(filtered_img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "      features = extract_features(filtered_img)\n",
    "      feature_vector.append(features)\n",
    "\n",
    "    hist = cv2.calcHist([img], [0], None, [16], [0, 256])\n",
    "    feature_vector.append(hist)\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_des_test = [Gabor_filter_extraction(img) for img in X_test] \n",
    "\n",
    "total_des_train = [Gabor_filter_extraction(img) for img in X_train] \n",
    "\n",
    "# reshape the filters\n",
    "tot_train_features = []\n",
    "\n",
    "for i in total_des_train:\n",
    "  x = np.hstack(i[:24])\n",
    "  z = i[-1].flatten()\n",
    "  w = np.concatenate((x,z))\n",
    "  tot_train_features.append(w)\n",
    "\n",
    "\n",
    "tot_test_features = []\n",
    "\n",
    "for i in total_des_test:\n",
    "  x = np.hstack(i[:24])\n",
    "  z = i[-1].flatten()\n",
    "  w = np.concatenate((x,z))\n",
    "  tot_test_features.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_test_features = np.array(tot_test_features)\n",
    "\n",
    "tot_train_features = np.array(tot_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(tot_train_features, y_train)\n",
    "\n",
    "score = clf.score(tot_test_features, y_test)\n",
    "print(\" Test accuracy: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " f1_score accuracy:  0.9014195287150482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "clf.fit(tot_train_features, y_train)\n",
    "\n",
    "# predict the target values for the test data\n",
    "y_pred = clf.predict(tot_test_features)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\" f1_score accuracy: \", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
