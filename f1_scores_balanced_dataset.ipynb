{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "X = np.load('/home/filsave/malviso/X.npy', allow_pickle=True)\n",
    "y = np.load('/home/filsave/malviso/y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(nfeatures, X_train, X_test, y_train, y_test):\n",
    "    detector = cv2.ORB_create(nfeatures)\n",
    "\n",
    "    total_kps_train= []\n",
    "    total_des_train= []\n",
    "    total_kps_test= []\n",
    "    total_des_test= []\n",
    "\n",
    "    for image in X_train:\n",
    "        query_kps, query_des = detector.detectAndCompute(image, None)\n",
    "        total_kps_train.append(query_kps)\n",
    "        total_des_train.append(query_des)\n",
    "\n",
    "    for image in X_test:\n",
    "        query_kps, query_des = detector.detectAndCompute(image, None)\n",
    "        total_kps_test.append(query_kps)\n",
    "        total_des_test.append(query_des)\n",
    "\n",
    "\n",
    "    null_indexes_train = []\n",
    "\n",
    "    for i,e in enumerate(total_des_train):\n",
    "        if e is None:\n",
    "            null_indexes_train.append(i)\n",
    "\n",
    "    total_des_train = np.delete(total_des_train, null_indexes_train).tolist()\n",
    "    y_train = np.delete(y_train,null_indexes_train).tolist()\n",
    "\n",
    "\n",
    "\n",
    "    null_indexes_test = []\n",
    "\n",
    "    for i,e in enumerate(total_des_test):\n",
    "        if e is None:\n",
    "            null_indexes_test.append(i)\n",
    "\n",
    "    total_des_test = np.delete(total_des_test, null_indexes_test).tolist() \n",
    "    y_test = np.delete(y_test,null_indexes_test).tolist()\n",
    "\n",
    "\n",
    "\n",
    "    max0 = 0\n",
    "    for des in total_des_train:\n",
    "        if des is not None:\n",
    "            if des.shape[0] > max0:\n",
    "                max0 = des.shape[0]\n",
    "\n",
    "    max1=0\n",
    "    for des in total_des_test:\n",
    "        if des is not None:\n",
    "            if des.shape[0] > max1:\n",
    "                max1 = des.shape[0]\n",
    "        \n",
    "    if max1 > max0:\n",
    "        max0=max1\n",
    "\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for des in total_des_train:\n",
    "        padding_to_add = max0 - des.shape[0]\n",
    "        if padding_to_add != 0:\n",
    "            pad_list = []\n",
    "            for k in range(32):\n",
    "                pad_list.append(0)\n",
    "            for j in range(padding_to_add):\n",
    "                total_des_train[i] = np.append(total_des_train[i], pad_list)\n",
    "            total_des_train[i] = np.array(total_des_train[i]).reshape(max0,32)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    for des in total_des_test:\n",
    "        padding_to_add = max0 - des.shape[0]\n",
    "        if padding_to_add != 0:\n",
    "            pad_list = []\n",
    "            for k in range(32):\n",
    "                pad_list.append(0)\n",
    "            for j in range(padding_to_add):\n",
    "                total_des_test[i] = np.append(total_des_test[i], pad_list)\n",
    "            total_des_test[i] = np.array(total_des_test[i]).reshape(max0,32)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for des in total_des_train:\n",
    "        total_des_train[i] = np.hstack(des)\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    for des in total_des_test:\n",
    "        total_des_test[i] = np.hstack(des)\n",
    "        i += 1\n",
    "\n",
    "    return total_des_train, total_des_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29  f1_score accuracy:  0.7290896564375042\n",
      "30  f1_score accuracy:  0.7275110107580987\n",
      "31  f1_score accuracy:  0.7310834909368789\n",
      "32  f1_score accuracy:  0.7303115503677827\n",
      "33  f1_score accuracy:  0.7580154466537814\n",
      "34  f1_score accuracy:  0.7344320978447312\n",
      "35  f1_score accuracy:  0.7360102432269007\n",
      "36  f1_score accuracy:  0.7278475666413255\n",
      "37  f1_score accuracy:  0.7460381432886023\n",
      "38  f1_score accuracy:  0.7444444207595875\n",
      "39  f1_score accuracy:  0.7404911981828506\n",
      "40  f1_score accuracy:  0.7429614088896936\n",
      "41  f1_score accuracy:  0.7295081443514866\n",
      "42  f1_score accuracy:  0.7404690916318823\n",
      "43  f1_score accuracy:  0.7287122894083844\n",
      "44  f1_score accuracy:  0.7210317006687764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for par in range(33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    total_des_train, total_des_test, y_train, y_test = get_values(par, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    clf.fit(total_des_train, y_train)\n",
    "\n",
    "    # predict the target values for the test data\n",
    "    y_pred = clf.predict(total_des_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(par, \" f1_score accuracy: \", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the best accuraxy was reached with 33 features. Interestingly enough this was close to the suggested number (32 by the robust paper) for one of th edescriptors method. This results is actually interesting to be compared to ORB. IF ORB is more suited that explain how sift suggest less features, being quite far from th enumber the authors described themself (40)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
